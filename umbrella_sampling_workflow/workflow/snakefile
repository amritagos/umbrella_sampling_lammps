import pandas as pd
from pathlib import Path
from snakemake.utils import min_version
import numpy as np


configfile: "config/general_config.yml"  # Path to config file containing general variables, relative to the workflow folder


# Load the sample data from the generated CSV file.
# IMPORTANT: Make sure to generate the samples.csv file with the generate_samples.py script!
samples = (
    pd.read_csv(config["samples"], dtype={"sample_name": str})
    .set_index("sample_name", drop=False)
    .sort_index()
)

SAMPLES_IDX_START = int(config.get("samples_idx_start", 0))
SAMPLES_IDX_END = int(config.get("samples_idx_end", len(samples)))

print(f"{SAMPLES_IDX_START=}")
print(f"{SAMPLES_IDX_END=}")

samples = samples[SAMPLES_IDX_START:SAMPLES_IDX_END]

NUM_THREADS = int(config["mpi_threads"])

min_version("6.0")

results_dir = config["results_dir"]

source_cmd = config["lammps"]["source_cmd"]

lmp = config["lammps"]["lmp_cmd"]


rule all:
    input:
        expand(
            "{results_dir}/equil/equilibrated.data",
            results_dir=results_dir,
            sample=samples.index,
        ),
        expand(
            "{results_dir}/umbrella_sampling/{sample}/inp.dat",
            results_dir=results_dir,
            sample=samples.index,
        ),
        expand(
            "{results_dir}/umbrella_sampling/{sample}/system.data",
            results_dir=results_dir,
            sample=samples.index,
        ),
        expand(
            "{results_dir}/wham_analysis/pmf.dat",
            results_dir=results_dir,
        ),
        expand(
            "{results_dir}/wham_analysis/pmf.png",
            results_dir=results_dir,
        ),


# Rule for running a LAMMPS script that can be inherited from
rule lammps_run:
    input:
        run_file=[],
    resources:
        cpus_per_task=1,
        ntasks_per_node=NUM_THREADS,
    threads: NUM_THREADS
    output:
        data=[],
        out=[],
    shell:
        f"""
        {source_cmd}
        export OMP_NUM_THREADS={{resources.cpus_per_task}}
        cd $( dirname {{input.run_file}})
        mpirun -n {{resources.ntasks_per_node}} {lmp} -in inp.dat 
        """


# Create a LAMMPS input file
rule lammps_input:
    localrule: True
    threads: 1
    input:
        template=[],
        potential_file=[],
    params:
        "",
    output:
        run_file=[],
    script:
        workflow.source_path("scripts/render_jinja2.py")


rule copy:
    """
    Copy multiple files into the output directory.
    - Creates directory if missing
    - Overwrites existing files (but keeps the directory)
    """
    localrule: True
    input:
        files=[],  # files to copy
        deps=[],  # optional dependencies that aren’t copied
    output:
        outfile=[],
    threads: 1
    run:
        import shutil
        from pathlib import Path

        outdir = Path(output.outfile).parent
        outdir.mkdir(parents=True, exist_ok=True)

        for f in input.files:
            src = Path(f)
            dst = outdir / src.name
            shutil.copy2(src, dst)  # overwrite if exists
            print(f"Copied {src} -> {dst}")


# -----------------------------------
# Equilibration


# TODO: add temperature as a parameter
# Create input file for equilibration
use rule lammps_input as lammps_input_equil with:
    localrule: True
    threads: 1
    retries: 1  # for latency on clusters 
    input:
        template=config["lammps"]["template_file"],
    params:
        equil=1,
        template_folder=config["template_folder_common"],
    output:
        run_file=ensure("{results_dir}/equil/inp.dat", non_empty=True),


# Run the equilibration
use rule lammps_run as lammps_run_equilibration with:
    input:
        run_file=rules.lammps_input_equil.output.run_file,
    threads: NUM_THREADS
    output:
        data="{results_dir}/equil/equilibrated.data",


# --------------------------------

# Umbrella sampling
# Create the windows and run, starting from the equilibrated configuration


# TODO: add temperature as a parameter
# Create an input file for the umbrella window
use rule lammps_input as lammps_input_umbrella with:
    localrule: True
    threads: 1
    retries: 1  # for latency on clusters 
    input:
        template=config["lammps"]["template_file"],
        data=rules.lammps_run_equilibration.output.data,
    params:
        umbrella_sampling=1,
        in_data=Path(f"{results_dir}/equil/equilibrated.data").resolve(),
        umbrella_spring_constant=config["umbrella_sampling"]["umbrella_spring_constant"],
        umbrella_center=lambda wc: samples.loc[wc.sample, "umbrella_center"],
        timestep=config["umbrella_sampling"]["timestep"],
        discard_steps=config["umbrella_sampling"]["discard_steps"],
        run_steps=config["umbrella_sampling"]["run_steps"],
        template_folder=config["template_folder_common"],
    output:
        run_file=ensure(
            "{results_dir}/umbrella_sampling/{sample}/inp.dat", non_empty=True
        ),


# Run the equilibration
use rule lammps_run as lammps_run_umbrella with:
    input:
        run_file=rules.lammps_input_umbrella.output.run_file,
    threads: NUM_THREADS
    output:
        data="{results_dir}/umbrella_sampling/{sample}/system.data",
        time_series="{results_dir}/umbrella_sampling/{sample}/umbrella-sampling.dat",


# -------------------------
# WHAM

# sort samples by run_number
sorted_samples = samples.sort_values("run_number").index


# Create the meta file which will contain all the time series information
rule create_wham_meta:
    localrule: True
    threads: 1
    input:
        time_series_paths=expand(
            rules.lammps_run_umbrella.output.time_series,
            results_dir=results_dir,
            sample=sorted_samples,
        ),
    output:
        wham_meta="{results_dir}/wham_analysis/umbrella-sampling.meta",
    params:
        abs_paths=lambda wc, input: [
            str(Path(p).resolve()) for p in input.time_series_paths
        ],
        umbrella_centers=[samples.loc[s, "umbrella_center"] for s in sorted_samples],
        spring_constants=[
            config["umbrella_sampling"]["umbrella_spring_constant"]
            for s in sorted_samples
        ],
    script:
        workflow.source_path("scripts/create_meta.py")


rule wham:
    localrule: True
    threads: 1
    input:
        wham_meta=rules.create_wham_meta.output.wham_meta,
    params:
        units="real",
        reaction_coordinate_min=-30,
        reaction_coordinate_max=30,
        nbins=50,
        tolerance=1e-8,
        temperature=119.8,  # in Kelvin (TODO: put in config)
        numpad=0,  # numpad specifies the number of “padding” values that should be printed for periodic free energy curve. This number should be set to 0 for aperiodic reaction coordinates.
    output:
        pmf="{results_dir}/wham_analysis/pmf.dat",
    log:
        "{results_dir}/wham_analysis/wham.log",
    shell:
        f"""
        wham units {{params.units}} {{params.reaction_coordinate_min}} {{params.reaction_coordinate_max}} {{params.nbins}} {{params.tolerance}} {{params.temperature}} {{params.numpad}} {{input.wham_meta}} {{output.pmf}} > {{log}} 2>&1
        """


umbrella_centers_sorted = [samples.loc[s, "umbrella_center"] for s in sorted_samples]


rule plot_pmf:
    localrule: True
    threads: 1
    input:
        pmf=rules.wham.output.pmf,
        time_series_paths=expand(
            rules.lammps_run_umbrella.output.time_series,
            results_dir=results_dir,
            sample=sorted_samples,
        ),
    params:
        abs_paths=lambda wc, input: [
            str(Path(p).resolve()) for p in input.time_series_paths
        ],
        xmin_pmf_plot=np.min(umbrella_centers_sorted) - 20,
        xmax_pmf_plot=np.max(umbrella_centers_sorted) + 20,
    output:
        histogram_plot="{results_dir}/wham_analysis/histograms.png",
        pmf_plot="{results_dir}/wham_analysis/pmf.png",
    script:
        workflow.source_path("scripts/plot_pmf_histo.py")
